{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_data():\n",
    "    url = \"s3://wagon-public-datasets/taxi-fare-train.csv\"\n",
    "    df = pd.read_csv(url, nrows=100)\n",
    "    return df\n",
    "\n",
    "def clean_df(df):\n",
    "    df = df.dropna(how='any', axis='rows')\n",
    "    df = df[(df.dropoff_latitude != 0) | (df.dropoff_longitude != 0)]\n",
    "    df = df[(df.pickup_latitude != 0) | (df.pickup_longitude != 0)]\n",
    "    if \"fare_amount\" in list(df):\n",
    "        df = df[df.fare_amount.between(0, 4000)]\n",
    "    df = df[df.passenger_count < 8]\n",
    "    df = df[df.passenger_count >= 0]\n",
    "    df = df[df[\"pickup_latitude\"].between(left=40, right=42)]\n",
    "    df = df[df[\"pickup_longitude\"].between(left=-74.3, right=-72.9)]\n",
    "    df = df[df[\"dropoff_latitude\"].between(left=40, right=42)]\n",
    "    df = df[df[\"dropoff_longitude\"].between(left=-74, right=-72.9)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_params = dict(\n",
    "  n_estimators=100,\n",
    "  max_depth=1)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.set_params(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = df[\"fare_amount\"]\n",
    "X_train = df.drop(\"fare_amount\", axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_distance(df, p,\n",
    "                       start_lat=\"pickup_latitude\",\n",
    "                       start_lon=\"pickup_longitude\",\n",
    "                       end_lat=\"dropoff_latitude\",\n",
    "                       end_lon=\"dropoff_longitude\"):\n",
    "    x1 = df[start_lon]\n",
    "    x2 = df[end_lon]\n",
    "    y1 = df[start_lat]\n",
    "    y2 = df[end_lat]\n",
    "    return ((abs(x2 - x1) ** p) + (abs(y2 - y1)) ** p) ** (1 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DistanceTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, distance_type=\"euclidian\", **kwargs):\n",
    "        self.distance_type = distance_type\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        if self.distance_type == \"haversine\":\n",
    "            X[\"distance\"] = haversine_vectorized(X)\n",
    "        if self.distance_type == \"euclidian\":\n",
    "            X[\"distance\"] = minkowski_distance(X, p=2)\n",
    "        if self.distance_type == \"manhattan\":\n",
    "            X[\"distance\"] = minkowski_distance(X, p=1)\n",
    "        return X[[\"distance\"]]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipe_distance = make_pipeline(\n",
    "    DistanceTransformer(),\n",
    "    StandardScaler())\n",
    "\n",
    "\n",
    "cols = [\"pickup_latitude\", \"pickup_longitude\", \"dropoff_latitude\", \"dropoff_longitude\"]\n",
    "\n",
    "feateng_blocks = [\n",
    "    ('distance', pipe_distance, cols),\n",
    "]\n",
    "\n",
    "features_encoder = ColumnTransformer(feateng_blocks)\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "            ('features', features_encoder),\n",
    "            ('model', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_rmse(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memoized_property import memoized_property\n",
    "\n",
    "import mlflow\n",
    "from  mlflow.tracking import MlflowClient\n",
    "\n",
    "class MLFlowBase():\n",
    "\n",
    "    def __init__(self, experiment_name, MLFLOW_URI):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.MLFLOW_URI = MLFLOW_URI\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_client(self):\n",
    "        mlflow.set_tracking_uri(self.MLFLOW_URI)\n",
    "        return MlflowClient()\n",
    "\n",
    "    @memoized_property\n",
    "    def mlflow_experiment_id(self):\n",
    "        try:\n",
    "            return self.mlflow_client \\\n",
    "                .create_experiment(self.experiment_name)\n",
    "        except BaseException:\n",
    "            return self.mlflow_client \\\n",
    "                .get_experiment_by_name(self.experiment_name).experiment_id\n",
    "\n",
    "    def mlflow_create_run(self):\n",
    "        self.mlflow_run = self.mlflow_client \\\n",
    "            .create_run(self.mlflow_experiment_id)\n",
    "\n",
    "    def mlflow_log_param(self, key, value):\n",
    "        self.mlflow_client \\\n",
    "            .log_param(self.mlflow_run.info.run_id, key, value)\n",
    "\n",
    "    def mlflow_log_metric(self, key, value):\n",
    "        self.mlflow_client \\\n",
    "            .log_metric(self.mlflow_run.info.run_id, key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, \n",
    "    param_grid={\n",
    "        'feat_eng_bloc__distance__robustscaler__copy': [True],\n",
    "        'regressor__min_samples_leaf': [3],\n",
    "        'regressor__oob_score': [True],\n",
    "        'regressor__min_weight_fraction_leaf': [0.0, 0.1]\n",
    "    },\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.score(X_test, y_test)\n",
    "\n",
    "grid_search.best_estimator_\n",
    "grid_search.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
